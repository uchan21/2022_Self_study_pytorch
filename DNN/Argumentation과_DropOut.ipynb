{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf98188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94cc9b",
   "metadata": {},
   "source": [
    "# Argumentation과 Dropout\n",
    "학습능력 향상을 위해 데이터 증진과 노드 드롭 아웃을 공부해보자!!\n",
    "---\n",
    "데이터는 많으면 많을수록 학습량이 많아져서 좋다...! Argumantation으로 기존 데이터를 변형해 데이터를 늘려보자!!      \n",
    "노드 드롭아웃은 각각의 노드들을 골고루 학습시켜 모든 노드의 파라미터들을 적절하게 맞춰준다.   \n",
    "책에 나온 말을 인용하자면 마치 대답을 잘하는 학생을 제외한 다른 학생에게 대답을 요구하는 상황...!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d68dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU, CPU를 맞춰주기 위한 코드\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d3aaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼 파라미터 설정\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f90dede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./.data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ecd292355f447c92dbbe0294ae0a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./.data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./.data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./.data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd0b6c897ec45829413b3531df522f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./.data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./.data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./.data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df8e9e128bd4dc9822f0075de2ca3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./.data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./.data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./.data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8295ff46ab143aeb18f756f135e6c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./.data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./.data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./.data',\n",
    "                    train = True,\n",
    "                    download = True,\n",
    "                    transform = transforms.Compose([\n",
    "                        transforms.RandomHorizontalFlip(),#데이터 증진을 위해 랜덤하게 좌우 반전을 시킨다.\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307),(0.3081)) #정규화 시켜주기\n",
    "                    ])),\n",
    "    batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "#테스트 데이터셋은 정규화만 시켜준다\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./.data',\n",
    "                    train = False,\n",
    "                    download = True,\n",
    "                    transform = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307),(0.3081))\n",
    "                    ])),\n",
    "    batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6764c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 선언하기\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, dropout_p): #드롭아웃을 받아올 것이다.\n",
    "        super(Net, self).__init__() #nn.Module 속성으로 초기화\n",
    "        self.fc1 = nn.Linear(784,256) # 입력값 맞춰서 레이어 만들고\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,10) #출력값 맞춰서 레이어 만든다.\n",
    "        self.dropout_p = dropout_p #드롭아웃도 설정해준다.\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,784) # 이미지를 랭크1로 펴준다.\n",
    "        x = F.relu(self.fc1(x)) # 엑티베이션은 relu를 사용한다.\n",
    "        \n",
    "        x = F.dropout(x, training=self.training, #신경망 출력 x, 학습인지를 알려주는 self.training\n",
    "                      p = self.dropout_p) #드롭아웃 확률을 설정한다\n",
    "        x = F.relu(self.fc2(x)) \n",
    "        x = F.dropout(x,training = self.training,\n",
    "                      p = self.dropout_p)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dfb4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(dropout_p=0.2).to(DEVICE) #모델을 생성한다.-드롭아웃을 같이 설정한다.\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01) #역전파를 위한 옵티마이저와 학습률도 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9e5d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer): #모델 학습을 위한 데피니션\n",
    "    model.train() \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data,target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad() #반복마다 새로운 기울기를 설정\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dddf7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader): # 모델 성능 확인을 위한 데피니션\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): #테스트는 기울기가 필요없음\n",
    "        for data,target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output,target, reduction = 'sum').item()\n",
    "            \n",
    "            pred = output.max(1,keepdim=True)[1]\n",
    "            correct +=pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    #오차와 정확도를 위한 equation\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct/len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79409c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test Loss: 0.5464, Accuracy: 82.21%\n",
      "[2] Test Loss: 0.4268, Accuracy: 86.41%\n",
      "[3] Test Loss: 0.3513, Accuracy: 89.19%\n",
      "[4] Test Loss: 0.2925, Accuracy: 91.32%\n",
      "[5] Test Loss: 0.2532, Accuracy: 92.27%\n",
      "[6] Test Loss: 0.2242, Accuracy: 93.12%\n",
      "[7] Test Loss: 0.2010, Accuracy: 93.83%\n",
      "[8] Test Loss: 0.1892, Accuracy: 94.30%\n",
      "[9] Test Loss: 0.1730, Accuracy: 94.76%\n",
      "[10] Test Loss: 0.1628, Accuracy: 94.87%\n",
      "[11] Test Loss: 0.1569, Accuracy: 95.08%\n",
      "[12] Test Loss: 0.1500, Accuracy: 95.29%\n",
      "[13] Test Loss: 0.1429, Accuracy: 95.54%\n",
      "[14] Test Loss: 0.1362, Accuracy: 95.72%\n",
      "[15] Test Loss: 0.1321, Accuracy: 95.78%\n",
      "[16] Test Loss: 0.1289, Accuracy: 95.96%\n",
      "[17] Test Loss: 0.1252, Accuracy: 96.15%\n",
      "[18] Test Loss: 0.1236, Accuracy: 96.04%\n",
      "[19] Test Loss: 0.1217, Accuracy: 96.06%\n",
      "[20] Test Loss: 0.1162, Accuracy: 96.22%\n",
      "[21] Test Loss: 0.1133, Accuracy: 96.34%\n",
      "[22] Test Loss: 0.1109, Accuracy: 96.36%\n",
      "[23] Test Loss: 0.1110, Accuracy: 96.39%\n",
      "[24] Test Loss: 0.1066, Accuracy: 96.55%\n",
      "[25] Test Loss: 0.1054, Accuracy: 96.63%\n",
      "[26] Test Loss: 0.1042, Accuracy: 96.60%\n",
      "[27] Test Loss: 0.1002, Accuracy: 96.71%\n",
      "[28] Test Loss: 0.1009, Accuracy: 96.60%\n",
      "[29] Test Loss: 0.0997, Accuracy: 96.65%\n",
      "[30] Test Loss: 0.0958, Accuracy: 96.89%\n",
      "[31] Test Loss: 0.0966, Accuracy: 96.90%\n",
      "[32] Test Loss: 0.0948, Accuracy: 96.92%\n",
      "[33] Test Loss: 0.0942, Accuracy: 96.97%\n",
      "[34] Test Loss: 0.0933, Accuracy: 96.87%\n",
      "[35] Test Loss: 0.0940, Accuracy: 96.82%\n",
      "[36] Test Loss: 0.0902, Accuracy: 97.03%\n",
      "[37] Test Loss: 0.0909, Accuracy: 97.05%\n",
      "[38] Test Loss: 0.0920, Accuracy: 97.00%\n",
      "[39] Test Loss: 0.0887, Accuracy: 97.03%\n",
      "[40] Test Loss: 0.0881, Accuracy: 97.06%\n",
      "[41] Test Loss: 0.0885, Accuracy: 97.17%\n",
      "[42] Test Loss: 0.0861, Accuracy: 97.22%\n",
      "[43] Test Loss: 0.0881, Accuracy: 97.06%\n",
      "[44] Test Loss: 0.0885, Accuracy: 97.15%\n",
      "[45] Test Loss: 0.0864, Accuracy: 97.22%\n",
      "[46] Test Loss: 0.0861, Accuracy: 97.29%\n",
      "[47] Test Loss: 0.0872, Accuracy: 97.26%\n",
      "[48] Test Loss: 0.0842, Accuracy: 97.31%\n",
      "[49] Test Loss: 0.0830, Accuracy: 97.31%\n",
      "[50] Test Loss: 0.0846, Accuracy: 97.30%\n"
     ]
    }
   ],
   "source": [
    "#모델 성능 테스트...!!\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    train(model,train_loader,optimizer)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch,test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90be9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
