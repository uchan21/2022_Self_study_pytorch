{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb5559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf3ab4e",
   "metadata": {},
   "source": [
    "# ResNet을 이용한 CNN\n",
    "ResNet을 따라해보고 더 깊은 컨볼루션 신경망을 만들어 봅시다..!\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5de1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30fc809",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30 #정확도를 올리고자 하면 에포크 수 늘리기!!\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21462696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./.data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f8761ed0dd4068b52f5612e068e460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./.data\\cifar-10-python.tar.gz to ./.data\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./.data',\n",
    "                     train = True,\n",
    "                     download=True,\n",
    "                     transform = transforms.Compose([\n",
    "                         transforms.RandomCrop(32,padding=4),\n",
    "                         transforms.RandomHorizontalFlip(),\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize((0.5,0.5,0.5),\n",
    "                                              (0.5,0.5,0.5))\n",
    "                     ])),\n",
    "    batch_size = BATCH_SIZE,shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./.data',\n",
    "                     train=False,\n",
    "                     transform = transforms.Compose([\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize((0.5,0.5,0.5),\n",
    "                                              (0.5,0.5,0.5))\n",
    "                     ])),\n",
    "    batch_size = BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18a13f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet은 여러개의 BasicBlock을 거쳐서 학습을 한다.\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride = 1):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3,\n",
    "                               stride = stride,padding=1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes,planes, kernel_size = 3,\n",
    "                               stride = 1, padding=1,bias =False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes) #정규화 함수이다.\n",
    "        self.shortcut = nn.Sequential() #ResNet과 일반적인 Convolution 신경망의 차이는 shortcut의 유무이다.\n",
    "        if stride !=1 or in_planes!=planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes,planes,kernel_size = 1, stride = stride, bias=False),\n",
    "                nn.BatchNorm2d(planes))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        #컨볼루션을 거친 후 숏컷으로 초기 정보를 이어붙이며 정보의 유실을 막을 수 있다.\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29284205",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self,num_classes = 10):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.in_planes=16\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3,16,kernel_size=3,\n",
    "                               stride = 1,padding =1,bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(16,2,stride=1) #블록으로 이루어진 층이라고 생각!!\n",
    "        self.layer2 = self._make_layer(32,2,stride=2)\n",
    "        self.layer3 = self._make_layer(64,2,stride=2)\n",
    "        self.linear = nn.Linear(64,num_classes)\n",
    "    \n",
    "    #코드를 읽어보면 이해할 수 있을것...!!\n",
    "    def _make_layer(self,planes, num_blocks, stride):\n",
    "        strides = [stride]+[1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(self.in_planes, planes,stride))#채널이 블록을 거치면서 바뀜\n",
    "            self.in_planes = planes #채널 맞춰주기\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out,8) #8*8차원에 8*8마스크를 씌우면 에버리지가 1개 나옴!! 채널이 64개니까 1*64개의 값들이 나옴\n",
    "        out = out.view(out.size(0),-1) #펴주고\n",
    "        out = self.linear(out) #마지막 레이어!!\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "500b9f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1,momentum=0.9,weight_decay=0.0005)\n",
    "#weight_decay = 가중치 감소 오버피팅을 막기 위한 방법!!\n",
    "#값이 너무 크면 언더피팅이 되므로 적절한 숫자를 사용해야 함!\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=50,gamma=0.1)\n",
    "#학습률 스케줄러 함수 - 에포크가 50마다 학습률에 감마값을 곱해 학습률을 낮춘다. (정교한 최적화가 가능!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea5e0134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data,target = data.to(DEVICE),target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31cbc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for data,target in test_loader:\n",
    "            data,target = data.to(DEVICE),target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            \n",
    "            pred = output.max(1,keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /=len(test_loader.dataset)\n",
    "    test_accuracy = 100.*correct/len(test_loader.dataset)\n",
    "    return test_loss,test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff349dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test Loss: 1.6700, Accuracy: 43.94%\n",
      "[2] Test Loss: 1.0342, Accuracy: 63.23%\n",
      "[3] Test Loss: 1.1096, Accuracy: 63.02%\n",
      "[4] Test Loss: 0.9667, Accuracy: 67.47%\n",
      "[5] Test Loss: 0.7976, Accuracy: 73.31%\n",
      "[6] Test Loss: 0.8817, Accuracy: 70.01%\n",
      "[7] Test Loss: 1.0680, Accuracy: 65.25%\n",
      "[8] Test Loss: 0.6918, Accuracy: 76.29%\n",
      "[9] Test Loss: 0.8107, Accuracy: 72.84%\n",
      "[10] Test Loss: 0.7032, Accuracy: 76.14%\n",
      "[11] Test Loss: 0.6987, Accuracy: 76.11%\n",
      "[12] Test Loss: 0.7445, Accuracy: 74.23%\n",
      "[13] Test Loss: 0.7576, Accuracy: 75.73%\n",
      "[14] Test Loss: 0.7172, Accuracy: 76.73%\n",
      "[15] Test Loss: 0.6074, Accuracy: 79.15%\n",
      "[16] Test Loss: 0.7032, Accuracy: 76.42%\n",
      "[17] Test Loss: 1.0110, Accuracy: 69.65%\n",
      "[18] Test Loss: 0.7756, Accuracy: 74.17%\n",
      "[19] Test Loss: 0.7374, Accuracy: 75.20%\n",
      "[20] Test Loss: 0.6574, Accuracy: 77.76%\n",
      "[21] Test Loss: 0.9144, Accuracy: 71.88%\n",
      "[22] Test Loss: 0.6309, Accuracy: 79.02%\n",
      "[23] Test Loss: 0.8681, Accuracy: 72.85%\n",
      "[24] Test Loss: 0.6096, Accuracy: 79.26%\n",
      "[25] Test Loss: 0.9411, Accuracy: 71.67%\n",
      "[26] Test Loss: 0.5842, Accuracy: 80.48%\n",
      "[27] Test Loss: 0.6201, Accuracy: 79.02%\n",
      "[28] Test Loss: 0.8476, Accuracy: 73.09%\n",
      "[29] Test Loss: 0.8015, Accuracy: 73.78%\n",
      "[30] Test Loss: 0.9821, Accuracy: 69.98%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,EPOCHS+1):\n",
    "    \n",
    "    train(model, train_loader,optimizer, epoch)\n",
    "    test_loss, test_accuracy = evaluate(model,test_loader)\n",
    "    scheduler.step()\n",
    "    \n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch, test_loss,test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e8f668",
   "metadata": {},
   "source": [
    "원래는 에포크를 늘려야 하지만 내 컴퓨터가 느려 에포크를 늘리면 학습이 내일 끝남...ㅠㅠ\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
